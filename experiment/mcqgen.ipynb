{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "##RAG pipeline With vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../requirements.txt'}, page_content='groq\\nlangchain\\nstreamlit\\npython-dotenv\\npyPDF2\\n\\n-e .')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Imgestion\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain , SequentialChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"../requirements.txt\")\n",
    "document=loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------> 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\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x1349bb527b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "print(\"-------->\",API_KEY)\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\") \n",
    "\n",
    "\n",
    "RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------> [Document(metadata={}, page_content='LangChain is a framework for developing applications powered by large language models (LLMs). \\nIt provides tools to manage, query, and retrieve relevant data from documents efficiently.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import os \n",
    "\n",
    "text = \"\"\"LangChain is a framework for developing applications powered by large language models (LLMs). \n",
    "It provides tools to manage, query, and retrieve relevant data from documents efficiently.\"\"\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "chunks=text_splitter.split_text(text)\n",
    "chunk_documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "print(\"-------------->\",chunk_documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"1\": {\"mcq\": \"What is data science?\", \"options\": {\"a\": \"A field that only uses statistics\", \"b\": \"An interdisciplinary field that uses statistics, computing, and domain knowledge\", \"c\": \"A field that only uses computer science and information science\", \"d\": \"A field that only uses mathematics and statistics\"}, \"correct\": \"b\"}, \"2\": {\"mcq\": \"What does data science integrate from the underlying application domain?\", \"options\": {\"a\": \"Only natural sciences\", \"b\": \"Domain knowledge from natural sciences, information technology, and medicine\", \"c\": \"Only information technology\", \"d\": \"Only medicine\"}, \"correct\": \"b\"}, \"3\": {\"mcq\": \"What is data science described as?\", \"options\": {\"a\": \"Only a science\", \"b\": \"A science, a research paradigm, a research method, a discipline, a workflow, and a profession\", \"c\": \"Only a research method\", \"d\": \"Only a discipline\"}, \"correct\": \"b\"}, \"4\": {\"mcq\": \"Who imagined data science as a 'fourth paradigm' of science?\", \"options\": {\"a\": \"Jim Gray\", \"b\": \"Nathan Yau\", \"c\": \"Ben Fry\", \"d\": \"Turing Award winner\"}, \"correct\": \"a\"}, \"5\": {\"mcq\": \"What is a data scientist?\", \"options\": {\"a\": \"A professional who only uses computer science\", \"b\": \"A professional who creates programming code and combines it with statistical knowledge\", \"c\": \"A professional who only uses mathematics\", \"d\": \"A professional who only uses statistics\"}, \"correct\": \"b\"}, \"6\": {\"mcq\": \"What does data science encompass?\", \"options\": {\"a\": \"Preparing data for analysis and developing data-driven solutions\", \"b\": \"Formulating data science problems and presenting findings\", \"c\": \"Preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings\", \"d\": \"Analyzing data and developing data-driven solutions\"}, \"correct\": \"c\"}, \"7\": {\"mcq\": \"What skills are incorporated in data science?\", \"options\": {\"a\": \"Computer science, statistics, information science, mathematics\", \"b\": \"Data visualization, information visualization, data sonification, data integration\", \"c\": \"Graphic design, complex systems, communication and business\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"8\": {\"mcq\": \"What is the link between data science and human–computer interaction?\", \"options\": {\"a\": \"Users should be able to control data\", \"b\": \"Users should be able to explore data\", \"c\": \"Users should be able to intuitively control and explore data\", \"d\": \"Users should not be able to interact with data\"}, \"correct\": \"c\"}, \"9\": {\"mcq\": \"Who identified database management, statistics and machine learning, and distributed and parallel systems as emerging foundational professional communities?\", \"options\": {\"a\": \"American Statistical Association\", \"b\": \"Nathan Yau\", \"c\": \"Ben Fry\", \"d\": \"Jim Gray\"}, \"correct\": \"a\"}, \"10\": {\"mcq\": \"What is the field of data science focused on?\", \"options\": {\"a\": \"Extracting knowledge from large data sets\", \"b\": \"Applying knowledge and insights to solve problems\", \"c\": \"Preparing data for analysis\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"11\": {\"mcq\": \"What does data science use to extract or extrapolate knowledge and insights?\", \"options\": {\"a\": \"Only structured data\", \"b\": \"Only unstructured data\", \"c\": \"Noisy, structured, and unstructured data\", \"d\": \"Only statistics\"}, \"correct\": \"c\"}, \"12\": {\"mcq\": \"What is the concept of data science?\", \"options\": {\"a\": \"To unify computer science and information science\", \"b\": \"To understand and analyze actual phenomena with data\", \"c\": \"To only use mathematics and statistics\", \"d\": \"To only use computer science and information science\"}, \"correct\": \"b\"}, \"13\": {\"mcq\": \"What fields does data science use techniques and theories from?\", \"options\": {\"a\": \"Mathematics, statistics, computer science, information science\", \"b\": \"Domain knowledge, mathematics, statistics, computer science\", \"c\": \"Information science, mathematics, statistics, domain knowledge\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"14\": {\"mcq\": \"What is the impact of information technology on science?\", \"options\": {\"a\": \"It has no impact\", \"b\": \"It has a small impact\", \"c\": \"It has a significant impact\", \"d\": \"It is changing science\"}, \"correct\": \"d\"}, \"15\": {\"mcq\": \"What is the 'fourth paradigm' of science?\", \"options\": {\"a\": \"Empirical\", \"b\": \"Theoretical\", \"c\": \"Computational\", \"d\": \"Data-driven\"}, \"correct\": \"d\"}, \"16\": {\"mcq\": \"What is a data-driven solution?\", \"options\": {\"a\": \"A solution that only uses computer science\", \"b\": \"A solution that only uses mathematics\", \"c\": \"A solution that uses data to solve problems\", \"d\": \"A solution that only uses statistics\"}, \"correct\": \"c\"}, \"17\": {\"mcq\": \"What is the role of a data scientist?\", \"options\": {\"a\": \"To only analyze data\", \"b\": \"To only develop data-driven solutions\", \"c\": \"To create insights from data\", \"d\": \"To only present findings\"}, \"correct\": \"c\"}, \"18\": {\"mcq\": \"What is data science focused on in a wide range of application domains?\", \"options\": {\"a\": \"Extracting knowledge from large data sets\", \"b\": \"Applying knowledge and insights to solve problems\", \"c\": \"Preparing data for analysis\", \"d\": \"Presenting findings\"}, \"correct\": \"b\"}, \"19\": {\"mcq\": \"What is the field of data science focused on in a wide range of application domains?\", \"options\": {\"a\": \"Preparing data for analysis and formulating data science problems\", \"b\": \"Analyzing data and developing data-driven solutions\", \"c\": \"Preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions\", \"d\": \"Presenting findings\"}, \"correct\": \"c\"}, \"20\": {\"mcq\": \"What skills are required in data science?\", \"options\": {\"a\": \"Computer science and statistics\", \"b\": \"Data visualization and information visualization\", \"c\": \"Graphic design and complex systems\", \"d\": \"All of the above and more\"}, \"correct\": \"d\"}}\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain , SequentialChain\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "client = ChatGroq(api_key=API_KEY, model=\"llama3-70b-8192\")\n",
    "\n",
    "\n",
    "clients = Groq(api_key=API_KEY)\n",
    "\n",
    "\n",
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(\"../src/Response.json\",\"r\") as f:\n",
    "    RESPONSE_JSON=json.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "quiz_generation_prompt=ChatPromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"],\n",
    "    messages=[ \n",
    "        {\"role\": \"user\", \"content\": TEMPLATE}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "quiz_chain=LLMChain(llm=client,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)\n",
    "\n",
    "     \n",
    "     \n",
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "quiz_evaluation_prompt=ChatPromptTemplate(\n",
    "    input_variables=[\"subject\",\"quiz\"],\n",
    "    messages=[ \n",
    "        {\"role\": \"user\", \"content\": TEMPLATE2}\n",
    "    ]\n",
    ")\n",
    "\n",
    "review_chain=LLMChain(llm=client,prompt=quiz_evaluation_prompt,output_key=\"review\",verbose=True)\n",
    "\n",
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain,review_chain] , input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"] , output_variables=[\"quiz\",\"review\"],verbose=True)\n",
    "\n",
    "PATH=\"../src/data.txt\"\n",
    "\n",
    "with open(PATH,\"r\") as file:\n",
    "   TEXT = file.read()\n",
    "   \n",
    "   \n",
    "generate_evaluate_chain\n",
    "\n",
    "TEXT\n",
    "NUMBER=20\n",
    "SUBJECT=\"AI\"\n",
    "TONE=\"Simple\"\n",
    "RESPONSE_JSON=RESPONSE_JSON\n",
    " \n",
    "\n",
    "def call_groq(prompt):\n",
    "    response = clients.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert MCQ creator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=3000\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "def generate_quiz_prompt(text, number, subject, tone, response_json):\n",
    "    return TEMPLATE.format(\n",
    "        text=text,\n",
    "        number=number,\n",
    "        subject=subject,\n",
    "        tone=tone,\n",
    "        RESPONSE_JSON=json.dumps(response_json)\n",
    "    ) \n",
    "\n",
    "quiz_prompt = generate_quiz_prompt(TEXT, NUMBER, SUBJECT, TONE, RESPONSE_JSON)\n",
    "mcq_response = call_groq(quiz_prompt) \n",
    "\n",
    "print(mcq_response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{datetime.now().strftime('%m_%d_%y_%H_%M_%S')}.log\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "LOG_FILE=\"{datetime.now().strftime('%m_%d_%y_%H_%M_%S')}.log\"\n",
    "print(LOG_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load---------------> [Document(metadata={'source': '../requirements.txt'}, page_content='groq\\nlangchain\\nstreamlit\\npython-dotenv\\npyPDF2\\n\\n-e .')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader \n",
    "\n",
    "load=TextLoader(\"../requirements.txt\")\n",
    "hghghhg=load.load()\n",
    "print(\"load--------------->\",hghghhg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.grammarly.com/blog/parts-of-speech/articles/#9'}, page_content='')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "## load,chunk and index the content of the html page\n",
    "\n",
    "loader=WebBaseLoader(web_paths=(\"https://www.grammarly.com/blog/parts-of-speech/articles/#9\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "\n",
    "                     )))\n",
    "\n",
    "text_documents=loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------> [Document(metadata={'producer': 'Adobe PDF Library 23.8.246', 'creator': 'Acrobat PDFMaker 23 for PowerPoint', 'creationdate': '2024-02-08T13:10:52-05:00', 'moddate': '2024-02-08T13:12:08-05:00', 'title': '1.3 Python as a Language', 'source': 'C:/Users/HP/Downloads/1.3 Python as a Language.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Introduction – Part 3 PYTHON FOR\\nEVERYBODY\\nParseltongue is the language of serpents \\nand those who can converse with them.\\nAn individual who can speak Parseltongue \\nis known as a Parselmouth. It is a very \\nuncommon skill, and may be hereditary. \\nNearly all known Parselmouths are \\ndescended from Salazar Slytherin.\\nhttp://harrypotter.wikia.com/wiki/Parseltongue'), Document(metadata={'producer': 'Adobe PDF Library 23.8.246', 'creator': 'Acrobat PDFMaker 23 for PowerPoint', 'creationdate': '2024-02-08T13:10:52-05:00', 'moddate': '2024-02-08T13:12:08-05:00', 'title': '1.3 Python as a Language', 'source': 'C:/Users/HP/Downloads/1.3 Python as a Language.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='Introduction – Part 3 PYTHON FOR\\nEVERYBODY\\nPython is the language of the Python Interpreter \\nand those who can converse with it. An individual \\nwho can speak Python is known as a Pythonista. \\nIt is a very uncommon skill, and may be \\nhereditary. Nearly all known Pythonistas use \\nsoftware initially developed by Guido van Rossum.\\nPython'), Document(metadata={'producer': 'Adobe PDF Library 23.8.246', 'creator': 'Acrobat PDFMaker 23 for PowerPoint', 'creationdate': '2024-02-08T13:10:52-05:00', 'moddate': '2024-02-08T13:12:08-05:00', 'title': '1.3 Python as a Language', 'source': 'C:/Users/HP/Downloads/1.3 Python as a Language.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='Introduction – Part 3 PYTHON FOR\\nEVERYBODY\\nEarly Learner: \\nSyntax Errors\\n• We need to learn the Python language so we can communicate our instructions to \\nPython.  In the beginning we will make lots of mistakes and speak gibberish like \\nsmall children.\\n• When you make a mistake, the computer does not think you are “cute”.  It says \\n“syntax error” - given that it knows the language and you are just learning it.  It \\nseems like Python is cruel and unfeeling.\\n• You must remember that you are intelligent and can learn. The computer is simple \\nand very fast, but cannot learn. So it is easier for you to learn Python than for the \\ncomputer to learn English...'), Document(metadata={'producer': 'Adobe PDF Library 23.8.246', 'creator': 'Acrobat PDFMaker 23 for PowerPoint', 'creationdate': '2024-02-08T13:10:52-05:00', 'moddate': '2024-02-08T13:12:08-05:00', 'title': '1.3 Python as a Language', 'source': 'C:/Users/HP/Downloads/1.3 Python as a Language.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='Introduction – Part 3 PYTHON FOR\\nEVERYBODY\\nTalking to Python')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"API_KEY\") \n",
    "file_path = \"C:/Users/HP/Downloads/1.3 Python as a Language.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "\n",
    "print(\"----------->\",pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'-----'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The `ar_csoc` table fields are:\\n\\n1. `id` - uuid, not null\\n2. `analysis_review_id` - uuid, not null\\n3. `csoc_id` - uuid, not null\\n4. `relevant_to_user_entity` - relevant_to_user_entity enum, not null\\n5. `user_entity_eval` - text\\n6. `status` - ar_item_status enum, not null\\n7. `reviewer_client_user_id` - uuid\\n8. `approver_client_user_id` - uuid\\n9. `reviewed_at` - timestamp without time zone, not null\\n10. `approved_at` - timestamp without time zone'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "client = ChatGroq(api_key=API_KEY,model=\"llama3-70b-8192\") \n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Provide me ar_csoc tabel fields :\\n\\n{context}\")]\n",
    ")\n",
    "\n",
    "chain = create_stuff_documents_chain(client, prompt)\n",
    "\n",
    "file_path = \"C:/Users/HP/Downloads/soc_coe_db_design_19 (1) (1) (1) (1) (1).pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "\n",
    "chain.invoke({\"context\": pages})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
